# -*- coding: utf-8 -*-
"""Read_Data_D1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10aGMt2q257FtGNzTJtx572dklZAnTzDJ
"""

from google.colab import drive
drive.mount("/content/gdrive")

import numpy as np
from glob import glob
import os
import pickle

ignore_header_number_lines = 10
num_long = 187
num_lat = 188
num_lines = num_long*num_lat
init_line_index = ignore_header_number_lines
long_line_index = init_line_index + num_long
fin_line_index = init_line_index + num_lines + 1

dir_names = np.array(glob("/content/gdrive/.shortcut-targets-by-id/1F0lLu4m_6tMBw5Ba1GGYY4pU8C2gFCFf/CD732-Datathon-1/*"))
print(dir_names)

grid_array = []
long_array = []
lat_array = []
date_array = []
max_array = []
min_array = []
dir_names = ["/content/gdrive/.shortcut-targets-by-id/1F0lLu4m_6tMBw5Ba1GGYY4pU8C2gFCFf/CD732-Datathon-1/SSHA",
 "/content/gdrive/.shortcut-targets-by-id/1F0lLu4m_6tMBw5Ba1GGYY4pU8C2gFCFf/CD732-Datathon-1/SSS",
 "/content/gdrive/.shortcut-targets-by-id/1F0lLu4m_6tMBw5Ba1GGYY4pU8C2gFCFf/CD732-Datathon-1/SST"]

for d, dname in enumerate(dir_names):
  grid = []
  check_extremes = 0
  filenames = np.array(glob(dname+"/*"))
  
  for k, curfile in enumerate(filenames):
    value_array = []
    if curfile[-3:] == "txt":
      with open(curfile) as fp:
        for i, line in enumerate(fp):
          if i >= init_line_index and i <= fin_line_index:
            result = [x.strip() for x in line.split(',')]
            value_array.append(float(result[4]))

            if d == 0:
              if i == init_line_index:
                print(str(d),str(i),str(long_line_index))
                date_array.append(result[0])
              if k == 0:
                if i < long_line_index:
                  long_array.append(float(result[2]))
                if (i-init_line_index)%num_long == 0:
                  lat_array.append(float(result[3]))
            
          elif i > fin_line_index:
            break

        print("value_array shape : {:}".format(np.shape(value_array)))
      
      for iv in range(len(value_array)):
        if(value_array[iv] == -1e34):
          value_array[iv] = np.nan
        
      if check_extremes == 0:
        max_array.append(np.nanmax(value_array))
        min_array.append(np.nanmin(value_array))
        check_extremes = 1

      else:
        max_array[d] = max(max_array[d], np.nanmax(value_array))
        min_array[d] = min(min_array[d], np.nanmin(value_array))
      
      grid.append((np.array(value_array)).reshape(num_lat,num_long))
      print("grid shape : {:}".format(np.shape(grid)))
  
  grid_array.append(grid)
  
  print("grid array shape : {:}".format(np.shape(grid_array)))

print(date_array)
print(long_array)
print(lat_array)
print(grid_array[0][0][0][:])

with open("/content/gdrive/My Drive/Datathon1/SSH-SSS-SST.pkl","wb") as pkl_file:
  pickle.dump(grid_array,pkl_file)

with open("/content/gdrive/My Drive/Datathon1/date-long-lat_1.pkl","wb") as pkl_dlt:
  pickle.dump([date_array,long_array,lat_array], pkl_dlt)

ignore_header_number_lines = 11
num_long = 181
num_lat = 189
num_lines = num_long*num_lat
init_line_index = ignore_header_number_lines
long_line_index = init_line_index + num_long
fin_line_index = init_line_index + num_lines + 1

grid_array = []
long_array = []
lat_array = []
date_array = []
max_array = []
depth_array = []
min_array = []
dir_names = ['/content/gdrive/.shortcut-targets-by-id/1F0lLu4m_6tMBw5Ba1GGYY4pU8C2gFCFf/CD732-Datathon-1/meridional-current',
 '/content/gdrive/.shortcut-targets-by-id/1F0lLu4m_6tMBw5Ba1GGYY4pU8C2gFCFf/CD732-Datathon-1/zonal-current']

for d, dname in enumerate(dir_names):
  grid = []
  check_extremes = 0
  filenames = np.array(glob(dname+"/*"))
  x = 0  
  for k, curfile in enumerate(filenames):
    value_array = []
    if curfile[-3:] == "txt":
      with open(curfile) as fp:
        for i, line in enumerate(fp):
          if i >= init_line_index and i <= fin_line_index:
            result = [x.strip() for x in line.split(',')]
            value_array.append(float(result[5]))
            depth_array.append(float(result[4]))

            if d == 0:
              if i == init_line_index:
                date_array.append(result[0])
              if k-x == 0:
                if i < long_line_index:
                  long_array.append(float(result[2]))
                if (i-init_line_index)%num_long == 0:
                  lat_array.append(float(result[3]))
            
          elif i > fin_line_index:
            break

        print("value_array shape : {:}".format(np.shape(value_array)))
      
      for iv in range(len(value_array)):
        if(value_array[iv] == -1e34):
          value_array[iv] = np.nan
        
      if check_extremes == 0:
        max_array.append(np.nanmax(value_array))
        min_array.append(np.nanmin(value_array))
        check_extremes = 1

      else:
        max_array[d] = max(max_array[d], np.nanmax(value_array))
        min_array[d] = min(min_array[d], np.nanmin(value_array))
      
      grid.append((np.array(value_array)).reshape(num_lat,num_long))
      print("grid shape : {:}".format(np.shape(grid)))

    else:
      x = 1
  grid_array.append(grid)  
  print("grid array shape : {:}".format(np.shape(grid_array)))

print(date_array)
print(long_array)
print(lat_array)
print(grid_array[0][0][0][:])

from collections import Counter
c = Counter(depth_array)
print(c.keys())

# depth is same so won't be using it.

with open("/content/gdrive/My Drive/Datathon1/meridonal_zonal.pkl","wb") as pkl_file:
  pickle.dump(grid_array,pkl_file)

with open("/content/gdrive/My Drive/Datathon1/date-long-lat_2.pkl","wb") as pkl_dlt:
  pickle.dump([date_array,long_array,lat_array], pkl_dlt)

print(grid_array[0][0][0][4])